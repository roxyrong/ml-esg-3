{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation with Reuter News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"reuters21578\",\"ModLewis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 19813 news.\n",
      "The dataset has 19595 news.\n",
      "The dataset has 17712 news.\n"
     ]
    }
   ],
   "source": [
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "df = pd.concat([train_df, test_df]).reset_index(drop=True)\n",
    "df = df[['text', 'text_type', \"title\"]]\n",
    "\n",
    "print(f\"The dataset has {len(df)} news.\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"The dataset has {len(df)} news.\")\n",
    "# cleaning up BRIEF and non-text\n",
    "df = df[df[\"text_type\"] == '\"NORM\"'].copy()\n",
    "print(f\"The dataset has {len(df)} news.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 17410 news.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    17410.000000\n",
       "mean       131.177714\n",
       "std        119.089422\n",
       "min         20.000000\n",
       "25%         60.000000\n",
       "50%         90.000000\n",
       "75%        163.000000\n",
       "max        713.000000\n",
       "Name: text_wc, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(sentence):\n",
    "    if sentence is not None:\n",
    "        return len(sentence.split(\" \"))\n",
    "    return 0\n",
    "\n",
    "df[\"text_wc\"] = df[\"text\"].apply(word_count)\n",
    "min_wc = np.percentile(df[\"text_wc\"], 1)\n",
    "max_wc = np.percentile(df[\"text_wc\"], 99)\n",
    "df = df[(df[\"text_wc\"] >= min_wc) & (df[\"text_wc\"] <= max_wc)].copy()\n",
    "print(f\"The dataset has {len(df)} news.\")\n",
    "df[\"text_wc\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, col):\n",
    "\n",
    "    # change to lower and remove spaces on either side\n",
    "    df[col] = df[col].apply(lambda x: x.lower().strip())\n",
    "    # remove ^lt > pattern\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'&lt;[^>]+>', '', x))\n",
    "    # remove extra spaces in between\n",
    "    df[col] = df[col].apply(lambda x: re.sub(' +', ' ', x))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_data(df, \"title\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"\\n\", \" \")\n",
    "df = clean_data(df, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter down to ESG related News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg',num_labels=4)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg',\n",
    "                                          truncation=True,\n",
    "                                          padding='max_length',\n",
    "                                          max_length=512)\n",
    "esg_pipeline = pipeline(\"text-classification\", \n",
    "                        model=finbert, \n",
    "                        tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 128\n",
    "for i in range(0, len(df) // batch + 1):\n",
    "    sentences = list(df.loc[i * batch: (i + 1) * batch][\"text\"])\n",
    "    sentences = [s[:512] for s in sentences]\n",
    "    results = esg_pipeline(sentences)\n",
    "    df.loc[i * batch: (i + 1) * batch, \"esg_label\"] = [x[\"label\"] for x in results]\n",
    "    df.loc[i * batch: (i + 1) * batch, \"esg_score\"] = [x[\"score\"] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../dataset/temp_reuter.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../dataset/temp_reuter.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esg_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Environmental</th>\n",
       "      <td>445.0</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>0.176262</td>\n",
       "      <td>0.330253</td>\n",
       "      <td>0.589691</td>\n",
       "      <td>0.750825</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.991086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Governance</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.522634</td>\n",
       "      <td>0.102706</td>\n",
       "      <td>0.350060</td>\n",
       "      <td>0.455747</td>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.590920</td>\n",
       "      <td>0.830855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>14314.0</td>\n",
       "      <td>0.938402</td>\n",
       "      <td>0.111449</td>\n",
       "      <td>0.335170</td>\n",
       "      <td>0.954603</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.991310</td>\n",
       "      <td>0.995978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>2562.0</td>\n",
       "      <td>0.753372</td>\n",
       "      <td>0.170418</td>\n",
       "      <td>0.346135</td>\n",
       "      <td>0.611664</td>\n",
       "      <td>0.777065</td>\n",
       "      <td>0.913833</td>\n",
       "      <td>0.988577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean       std       min       25%       50%  \\\n",
       "esg_label                                                                  \n",
       "Environmental    445.0  0.737755  0.176262  0.330253  0.589691  0.750825   \n",
       "Governance        89.0  0.522634  0.102706  0.350060  0.455747  0.492664   \n",
       "None           14314.0  0.938402  0.111449  0.335170  0.954603  0.984908   \n",
       "Social          2562.0  0.753372  0.170418  0.346135  0.611664  0.777065   \n",
       "\n",
       "                    75%       max  \n",
       "esg_label                          \n",
       "Environmental  0.907906  0.991086  \n",
       "Governance     0.590920  0.830855  \n",
       "None           0.991310  0.995978  \n",
       "Social         0.913833  0.988577  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"esg_label\")[\"esg_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2741 augmented news.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esg_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Environmental</th>\n",
       "      <td>393.0</td>\n",
       "      <td>0.775998</td>\n",
       "      <td>0.149653</td>\n",
       "      <td>0.504137</td>\n",
       "      <td>0.649648</td>\n",
       "      <td>0.783682</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.991086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Governance</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.611769</td>\n",
       "      <td>0.084351</td>\n",
       "      <td>0.503932</td>\n",
       "      <td>0.543160</td>\n",
       "      <td>0.595629</td>\n",
       "      <td>0.662771</td>\n",
       "      <td>0.830855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>2308.0</td>\n",
       "      <td>0.786391</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.501986</td>\n",
       "      <td>0.659425</td>\n",
       "      <td>0.811584</td>\n",
       "      <td>0.922440</td>\n",
       "      <td>0.988577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std       min       25%       50%  \\\n",
       "esg_label                                                                 \n",
       "Environmental   393.0  0.775998  0.149653  0.504137  0.649648  0.783682   \n",
       "Governance       40.0  0.611769  0.084351  0.503932  0.543160  0.595629   \n",
       "Social         2308.0  0.786391  0.145179  0.501986  0.659425  0.811584   \n",
       "\n",
       "                    75%       max  \n",
       "esg_label                          \n",
       "Environmental  0.919137  0.991086  \n",
       "Governance     0.662771  0.830855  \n",
       "Social         0.922440  0.988577  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter down\n",
    "df = df[(df[\"esg_label\"] != \"None\") & (df[\"esg_score\"] > 0.5)]\n",
    "print(f\"There are {len(df)} augmented news.\")\n",
    "df.groupby(\"esg_label\")[\"esg_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../dataset/temp_reuter_filtered.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPT 4 to further filter related news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Given the following news, output -1 if the news is not related to ESG (environmental, social, and governance) and won't have any ESG impact. Output 0 if the ESG impact duration is below 2 years, 1 if the ESG impact duration is between 2 and 5 year and 2 if the ESG impact duration is more than 5 years. You only need to output the number, and do not need any further explanation.\n",
    "\n",
    "News:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_label(sentence, model):\n",
    "    content = template + sentence\n",
    "    \n",
    "    conversation = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an ESG analyst, skilled assessing the level and duration an event in the news article might have on the company\"},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=conversation,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    message = completion.choices[0].message.content\n",
    "    \n",
    "    try:\n",
    "        return int(message)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gpt_4_lable\"] = df[\"text\"].apply(generate_gpt_label)\n",
    "\n",
    "df.to_parquet(\"../dataset/temp_reuter_openai_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../dataset/temp_reuter_openai_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We generate labels for 847 news.\n",
      "And there are 1894 news not related to ESG.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "esg_label      gpt_4_label\n",
       "Environmental  -1              149\n",
       "                0               38\n",
       "                1               99\n",
       "                2              107\n",
       "Governance     -1               28\n",
       "                1               11\n",
       "                2                1\n",
       "Social         -1             1717\n",
       "                0              128\n",
       "                1              420\n",
       "                2               43\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"We generate labels for {len(df[df['gpt_4_label'] != -1])} news.\")\n",
    "print(f\"And there are {len(df[df['gpt_4_label'] == -1])} news not related to ESG.\")\n",
    "df.groupby([\"esg_label\",\"gpt_4_label\"])[\"text\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"gpt_4_label\"] != -1].reset_index()\n",
    "\n",
    "df.to_parquet(\"../dataset/reuter_gpt4_label.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../dataset/temp_reuter_openai_filtered.parquet\")\n",
    "df_pythia = pd.read_parquet(\"../dataset/temp_reuter_pythia_filtered.parquet\").reset_index(drop=True)\n",
    "df_neox = pd.read_parquet(\"../dataset/temp_reuter_neox_filtered.parquet\").reset_index(drop=True)\n",
    "df_gemini = pd.read_parquet(\"../dataset/temp_reuter_gemini_filtered.parquet\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pythia[\"pythia_label\"] = df_pythia[\"pythia_label\"].fillna(-1)\n",
    "df_neox[\"neox_label\"] = df_neox[\"neox_label\"].fillna(-1)\n",
    "df_gemini[\"gemini_label\"] = df_gemini[\"gemini_label\"].fillna(-1)\n",
    "\n",
    "df_pythia[\"pythia_label\"] = df_pythia[\"pythia_label\"].astype(int)\n",
    "df_neox[\"neox_label\"] = df_neox[\"neox_label\"].astype(int)\n",
    "df_gemini[\"gemini_label\"] = df_gemini[\"gemini_label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pythia_label\n",
       "-1     117\n",
       " 0    1185\n",
       " 1    1439\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pythia.groupby(\"pythia_label\")[\"text\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neox_label\n",
       "-1       4\n",
       " 0     160\n",
       " 1    1331\n",
       " 2    1246\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neox.groupby(\"neox_label\")[\"text\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gemini_label\n",
       "-1    2447\n",
       " 0      51\n",
       " 1      92\n",
       " 2     151\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gemini.groupby(\"gemini_label\")[\"text\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = df.merge(df_pythia).merge(df_neox).merge(df_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 646 news with valid label.\n"
     ]
    }
   ],
   "source": [
    "aggregated_df = aggregated_df[((aggregated_df[\"gpt_4_label\"] == aggregated_df[\"pythia_label\"]) | \n",
    "                               (aggregated_df[\"gpt_4_label\"] == aggregated_df[\"neox_label\"]) | \n",
    "                               (aggregated_df[\"gpt_4_label\"] == aggregated_df[\"gemini_label\"])) & \n",
    "                              (aggregated_df[\"gpt_4_label\"] != -1)].reset_index(drop=True)\n",
    "print(f\"There are {len(aggregated_df)} news with valid label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sentences(sentences, sent_size):\n",
    "    return [sentences[i : i + sent_size] for i in range(0, len(sentences), sent_size)]\n",
    "\n",
    "def segment_articles(df, sent_size):\n",
    "    df['sent_tokenize'] = df['text'].apply(sent_tokenize)\n",
    "    df['new_text'] = df['sent_tokenize'].apply(lambda x: group_sentences(x, sent_size))\n",
    "    seg_df = df.explode('new_text')\n",
    "    seg_df[\"new_text\"] = seg_df[\"new_text\"].apply(lambda x: \" \".join(x))\n",
    "    seg_df = seg_df.drop(columns=\"sent_tokenize\")\n",
    "    return seg_df\n",
    "    \n",
    "# segment Chinese and Korean articles\n",
    "sent_size = 5\n",
    "aggregated_df = segment_articles(aggregated_df, sent_size)\n",
    "aggregated_df[\"text_wc\"] = aggregated_df[\"new_text\"].apply(word_count)\n",
    "aggregated_df = aggregated_df[(aggregated_df[\"text_wc\"] > 10)]\n",
    "aggregated_df = aggregated_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1221 news with valid label and text length.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpt_4_label\n",
       "0    186\n",
       "1    858\n",
       "2    177\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"There are {len(aggregated_df)} news with valid label and text length.\")\n",
    "aggregated_df.groupby([\"gpt_4_label\"])[\"text\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = aggregated_df.rename(columns = {\"new_text\": \"content\", \n",
    "                                                \"gpt_4_label\": \"label\"})\n",
    "aggregated_df[\"feature\"] = aggregated_df[\"title\"] + \" || \" + aggregated_df[\"content\"]\n",
    "aggregated_df[\"group_indicator\"] = -1\n",
    "aggregated_df[\"language\"] = \"English\"\n",
    "\n",
    "columns = [\"title\", \"content\", \"feature\", \"label\", \"group_indicator\", \"language\"]\n",
    "aggregated_df = aggregated_df[columns]\n",
    "\n",
    "aggregated_df.to_parquet(\"../dataset/augmentation_dataset.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
