{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/xinyunrong/Desktop/code/ml-esg-3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load translated data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file has 2320 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>impact_length_idx</th>\n",
       "      <th>language</th>\n",
       "      <th>title_eng</th>\n",
       "      <th>content_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>ESG-focused financial technology company Arabe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>ESG-focused financial technology company Arabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>The company also announced the appointment of ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>The company also announced the appointment of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>Wong said:  “Personalised portfolios demand th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
       "      <td>Wong said:  “Personalised portfolios demand th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.esgtoday.com/ukraine-war-inflation...</td>\n",
       "      <td>Ukraine War, Inflation Reduction Act Driving F...</td>\n",
       "      <td>One of the key themes of the report is the imp...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Ukraine War, Inflation Reduction Act Driving F...</td>\n",
       "      <td>One of the key themes of the report is the imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.esgtoday.com/eu-regulators-welcome...</td>\n",
       "      <td>EU Regulators Welcome, Critique New European S...</td>\n",
       "      <td>Europe’s three primary financial regulatory ag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>English</td>\n",
       "      <td>EU Regulators Welcome, Critique New European S...</td>\n",
       "      <td>Europe’s three primary financial regulatory ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.esgtoday.com/arabesque-ai-appoints...   \n",
       "1  https://www.esgtoday.com/arabesque-ai-appoints...   \n",
       "2  https://www.esgtoday.com/arabesque-ai-appoints...   \n",
       "3  https://www.esgtoday.com/ukraine-war-inflation...   \n",
       "4  https://www.esgtoday.com/eu-regulators-welcome...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "1  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "2  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "3  Ukraine War, Inflation Reduction Act Driving F...   \n",
       "4  EU Regulators Welcome, Critique New European S...   \n",
       "\n",
       "                                             content  impact_length_idx  \\\n",
       "0  ESG-focused financial technology company Arabe...                1.0   \n",
       "1  The company also announced the appointment of ...                1.0   \n",
       "2  Wong said:  “Personalised portfolios demand th...                1.0   \n",
       "3  One of the key themes of the report is the imp...                2.0   \n",
       "4  Europe’s three primary financial regulatory ag...                0.0   \n",
       "\n",
       "  language                                          title_eng  \\\n",
       "0  English  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "1  English  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "2  English  Arabesque AI Appoints Carolina Minio Paluello ...   \n",
       "3  English  Ukraine War, Inflation Reduction Act Driving F...   \n",
       "4  English  EU Regulators Welcome, Critique New European S...   \n",
       "\n",
       "                                         content_eng  \n",
       "0  ESG-focused financial technology company Arabe...  \n",
       "1  The company also announced the appointment of ...  \n",
       "2  Wong said:  “Personalised portfolios demand th...  \n",
       "3  One of the key themes of the report is the imp...  \n",
       "4  Europe’s three primary financial regulatory ag...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trs = pd.read_parquet(\"../dataset/Translation_Dataset.parquet\")\n",
    "print(f\"This file has {len(df_trs)} samples.\")\n",
    "df_trs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_wc</th>\n",
       "      <th>content_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2320.000000</td>\n",
       "      <td>2320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.267672</td>\n",
       "      <td>365.278017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.988230</td>\n",
       "      <td>405.737352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title_wc   content_wc\n",
       "count  2320.000000  2320.000000\n",
       "mean     14.267672   365.278017\n",
       "std       5.988230   405.737352\n",
       "min       4.000000     8.000000\n",
       "25%      11.000000    74.000000\n",
       "50%      13.000000   125.000000\n",
       "75%      16.000000   577.000000\n",
       "max      48.000000  3974.000000"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def word_count(article):\n",
    "    return len(regexp_tokenizer.tokenize(article))\n",
    "    \n",
    "\n",
    "df_trs[\"title_wc\"] = df_trs[\"title_eng\"].apply(word_count)\n",
    "df_trs[\"content_wc\"] = df_trs[\"content_eng\"].apply(word_count)\n",
    "\n",
    "df_trs[[\"title_wc\", \"content_wc\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count       mean       std  min   25%   50%   75%   max\n",
      "language                                                         \n",
      "Chinese   352.0  24.309659  7.916093  4.0  19.0  24.0  30.0  48.0\n",
      "English   545.0  11.400000  2.934581  5.0   9.0  11.0  13.0  21.0\n",
      "French    654.0  13.172783  3.088157  7.0  11.0  13.0  15.0  22.0\n",
      "Korean    769.0  12.634590  3.111705  4.0  11.0  12.0  15.0  25.0\n",
      "          count        mean         std    min    25%    50%     75%     max\n",
      "language                                                                    \n",
      "Chinese   352.0  925.994318  524.688593  173.0  564.5  764.0  1171.5  3974.0\n",
      "English   545.0   63.425688   27.222302    8.0   44.0   59.0    80.0   194.0\n",
      "French    654.0   84.678899   23.265120   16.0   69.0   84.0    98.0   225.0\n",
      "Korean    769.0  561.180754  236.733538  144.0  388.0  519.0   693.0  1455.0\n"
     ]
    }
   ],
   "source": [
    "# Korean and Chinese dataset are too long, indicating the needs to further segmenation\n",
    "\n",
    "print(df_trs.groupby(\"language\")[\"title_wc\"].describe())\n",
    "print(df_trs.groupby(\"language\")[\"content_wc\"].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Segment Chinese and Korean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment Chinese and Korean articles into every n sentences as they are too long\n",
    "\n",
    "def group_sentences(sentences, sent_size):\n",
    "    return [sentences[i : i + sent_size] for i in range(0, len(sentences), sent_size)]\n",
    "\n",
    "def segment_articles(df, sent_size):\n",
    "    df['sent_tokenize'] = df['content_eng'].apply(sent_tokenize)\n",
    "    df['content_eng_short'] = df['sent_tokenize'].apply(lambda x: group_sentences(x, sent_size))\n",
    "    seg_df = df.explode('content_eng_short')\n",
    "    seg_df[\"content_eng_short\"] = seg_df[\"content_eng_short\"].apply(lambda x: \" \".join(x))\n",
    "    seg_df = seg_df.drop(columns=\"sent_tokenize\")\n",
    "    return seg_df\n",
    "\n",
    "# split the dataset to segment\n",
    "chn_kor_trs = df_trs[df_trs[\"language\"].isin([\"Korean\", \"Chinese\"])].copy()\n",
    "eng_fre_trs = df_trs[~df_trs[\"language\"].isin([\"Korean\", \"Chinese\"])].copy()\n",
    "    \n",
    "# segment Chinese and Korean articles\n",
    "sent_size = 5\n",
    "chn_kor_seg = segment_articles(chn_kor_trs, sent_size)\n",
    "chn_kor_seg[\"content_wc\"] = chn_kor_seg[\"content_eng_short\"].apply(word_count)\n",
    "\n",
    "# concatenate with English and French articles\n",
    "eng_fre_seg = eng_fre_trs\n",
    "eng_fre_seg[\"content_eng_short\"] = eng_fre_seg[\"content_eng\"]\n",
    "\n",
    "df_seg = pd.concat([chn_kor_seg, eng_fre_seg]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting 1121 Korean & Chinese samples into 5447 samples.\n",
      "Expanding 2320 samples to 6646 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chinese</th>\n",
       "      <td>1924.0</td>\n",
       "      <td>169.412682</td>\n",
       "      <td>64.362227</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>545.0</td>\n",
       "      <td>63.425688</td>\n",
       "      <td>27.222302</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>654.0</td>\n",
       "      <td>84.678899</td>\n",
       "      <td>23.265120</td>\n",
       "      <td>16.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korean</th>\n",
       "      <td>3523.0</td>\n",
       "      <td>122.494465</td>\n",
       "      <td>41.591435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean        std   min    25%    50%    75%    max\n",
       "language                                                                 \n",
       "Chinese   1924.0  169.412682  64.362227   2.0  130.0  170.0  207.0  425.0\n",
       "English    545.0   63.425688  27.222302   8.0   44.0   59.0   80.0  194.0\n",
       "French     654.0   84.678899  23.265120  16.0   69.0   84.0   98.0  225.0\n",
       "Korean    3523.0  122.494465  41.591435   2.0   99.0  124.0  150.0  336.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Segmenting {len(chn_kor_trs)} Korean & Chinese samples into {len(chn_kor_seg)} samples.\")\n",
    "print(f\"Expanding {len(df_trs)} samples to {len(df_seg)} samples.\")\n",
    "df_seg.groupby(\"language\")[\"content_wc\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>esg_label</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>feature</th>\n",
       "      <th>group_indicator</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "      <td>Date: 2022-01-04 work-life balance in the mode...</td>\n",
       "      <td>Social</td>\n",
       "      <td>0.975503</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "      <td>0</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>Date: 2021-09-06Two years ago, IAA Mobility wa...</td>\n",
       "      <td>Social</td>\n",
       "      <td>0.732907</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>One is the new EQE, which is positioned under ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.749639</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>Teaser photo of the interior of the new Merced...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.631160</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>The Mercedes-AMG GT 63 S E Performance is AMG'...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.863756</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label language                                              title  \\\n",
       "0    2.0  Chinese  Is the boss himself a punch card machine? Bill...   \n",
       "1    0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "2    0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "3    0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "4    0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "\n",
       "                                             content esg_label  esg_score  \\\n",
       "0  Date: 2022-01-04 work-life balance in the mode...    Social   0.975503   \n",
       "1  Date: 2021-09-06Two years ago, IAA Mobility wa...    Social   0.732907   \n",
       "2  One is the new EQE, which is positioned under ...      None   0.749639   \n",
       "3  Teaser photo of the interior of the new Merced...      None   0.631160   \n",
       "4  The Mercedes-AMG GT 63 S E Performance is AMG'...      None   0.863756   \n",
       "\n",
       "                                             feature  group_indicator  \\\n",
       "0  Is the boss himself a punch card machine? Bill...                0   \n",
       "1  Mercedes-Maybach is going electric too, with t...                1   \n",
       "2  Mercedes-Maybach is going electric too, with t...                1   \n",
       "3  Mercedes-Maybach is going electric too, with t...                1   \n",
       "4  Mercedes-Maybach is going electric too, with t...                1   \n",
       "\n",
       "                                            features  \n",
       "0  Is the boss himself a punch card machine? Bill...  \n",
       "1  Mercedes-Maybach is going electric too, with t...  \n",
       "2  Mercedes-Maybach is going electric too, with t...  \n",
       "3  Mercedes-Maybach is going electric too, with t...  \n",
       "4  Mercedes-Maybach is going electric too, with t...  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataset for data augmentation\n",
    "df_seg = df_seg.drop(columns=['url', 'title', 'content', 'content_eng', 'title_wc', 'content_wc'])\n",
    "\n",
    "df_seg = df_seg.rename(columns={\n",
    "    \"title_eng\": \"title\",\n",
    "    \"content_eng_short\": \"content\",\n",
    "    \"impact_length_idx\": \"label\"\n",
    "})\n",
    "\n",
    "df_seg[\"features\"] = df_seg[\"title\"] + ' || ' + df_seg[\"content\"]\n",
    "\n",
    "df_seg.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Filter non-ESG related sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg',num_labels=4)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg',\n",
    "                                          truncation=True,\n",
    "                                          padding='max_length',\n",
    "                                          max_length=512)\n",
    "esg_pipeline = pipeline(\"text-classification\", \n",
    "                        model=finbert, \n",
    "                        tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "for i in range(0, len(df_seg) // batch + 1):\n",
    "    sentences = list(df_seg.loc[i * batch: (i + 1) * batch][\"content\"])\n",
    "    sentences = [s[:512] for s in sentences]\n",
    "    results = esg_pipeline(sentences)\n",
    "    df_seg.loc[i * batch: (i + 1) * batch, \"esg_label\"] = [x[\"label\"] for x in results]\n",
    "    df_seg.loc[i * batch: (i + 1) * batch, \"esg_score\"] = [x[\"score\"] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 149 samples that are not ESG related with over 0.9 probability.\n"
     ]
    }
   ],
   "source": [
    "# Filter out segmented Chinese and Korean paragraphs that are non ESG related.\n",
    "\n",
    "none_news = df_seg[(df_seg[\"esg_label\"] == \"None\") & (df_seg[\"esg_score\"] > 0.9) & (df_seg[\"language\"].isin([\"Chinese\", \"Korean\"]))]\n",
    "print(f\"There are {len(none_news)} samples that are not ESG related with over 0.9 probability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We filter down to 5966 samples.\n"
     ]
    }
   ],
   "source": [
    "df_seg = df_seg[~df_seg.index.isin(none_news.index)].reset_index(drop=True)\n",
    "print(f\"We filter down to {len(df_seg)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = df_seg.drop(columns=[\"esg_label\", \"esg_score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    2087\n",
       "1.0    1317\n",
       "2.0    2562\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seg.groupby(\"label\")[\"label\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign group id for each title before train test split\n",
    "groups = list(df_seg[\"title\"].unique())\n",
    "group_indic_dict = {}\n",
    "for i, v in enumerate(groups):\n",
    "    group_indic_dict[v] = i\n",
    "    \n",
    "df_seg[\"group_indicator\"] = df_seg[\"title\"].map(group_indic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    559\n",
       "1.0    353\n",
       "2.0    655\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seg.groupby(\"group_indicator\").head(1).groupby(\"label\")[\"label\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data ensuring the same group is not in both train and test sets\n",
    "for train_idx, test_idx in gss.split(df_seg['feature'], \n",
    "                                     df_seg['label'], \n",
    "                                     df_seg['group_indicator']):\n",
    "    train_set = df_seg.iloc[train_idx]\n",
    "    valid_set = df_seg.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    1663\n",
      "1.0    1015\n",
      "2.0    2023\n",
      "Name: label, dtype: int64\n",
      "label\n",
      "0.0    424\n",
      "1.0    302\n",
      "2.0    539\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.groupby(\"label\")[\"label\"].count())\n",
    "print(valid_set.groupby(\"label\")[\"label\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "Chinese    1323\n",
      "English     431\n",
      "French      525\n",
      "Korean     2422\n",
      "Name: label, dtype: int64\n",
      "language\n",
      "Chinese    387\n",
      "English    108\n",
      "French     129\n",
      "Korean     641\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.groupby(\"language\")[\"label\"].count())\n",
    "print(valid_set.groupby(\"language\")[\"label\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>group_indicator</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "      <td>Date: 2022-01-04 work-life balance in the mode...</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "      <td>0</td>\n",
       "      <td>Is the boss himself a punch card machine? Bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>Date: 2021-09-06Two years ago, IAA Mobility wa...</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>One is the new EQE, which is positioned under ...</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>Teaser photo of the interior of the new Merced...</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>The Mercedes-AMG GT 63 S E Performance is AMG'...</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mercedes-Maybach is going electric too, with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>0.0</td>\n",
       "      <td>French</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>It's a return to the long haul that's attracti...</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>1504</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>0.0</td>\n",
       "      <td>French</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>Sailing \"contributes to a more virtuous mix \"U...</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>1504</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>0.0</td>\n",
       "      <td>French</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>It costs 180 euros and 24 hours to reach Corsi...</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>1504</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>0.0</td>\n",
       "      <td>French</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>\"You're reconsidering your relationship with t...</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>1504</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>0.0</td>\n",
       "      <td>French</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>And tourists aren't the only ones turning to t...</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "      <td>1504</td>\n",
       "      <td>An ecological alternative to air travel, sailb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4701 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label language                                              title  \\\n",
       "0       2.0  Chinese  Is the boss himself a punch card machine? Bill...   \n",
       "1       0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "2       0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "3       0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "4       0.0  Chinese  Mercedes-Maybach is going electric too, with t...   \n",
       "...     ...      ...                                                ...   \n",
       "5955    0.0   French  An ecological alternative to air travel, sailb...   \n",
       "5956    0.0   French  An ecological alternative to air travel, sailb...   \n",
       "5957    0.0   French  An ecological alternative to air travel, sailb...   \n",
       "5958    0.0   French  An ecological alternative to air travel, sailb...   \n",
       "5959    0.0   French  An ecological alternative to air travel, sailb...   \n",
       "\n",
       "                                                content  \\\n",
       "0     Date: 2022-01-04 work-life balance in the mode...   \n",
       "1     Date: 2021-09-06Two years ago, IAA Mobility wa...   \n",
       "2     One is the new EQE, which is positioned under ...   \n",
       "3     Teaser photo of the interior of the new Merced...   \n",
       "4     The Mercedes-AMG GT 63 S E Performance is AMG'...   \n",
       "...                                                 ...   \n",
       "5955  It's a return to the long haul that's attracti...   \n",
       "5956  Sailing \"contributes to a more virtuous mix \"U...   \n",
       "5957  It costs 180 euros and 24 hours to reach Corsi...   \n",
       "5958  \"You're reconsidering your relationship with t...   \n",
       "5959  And tourists aren't the only ones turning to t...   \n",
       "\n",
       "                                                feature  group_indicator  \\\n",
       "0     Is the boss himself a punch card machine? Bill...                0   \n",
       "1     Mercedes-Maybach is going electric too, with t...                1   \n",
       "2     Mercedes-Maybach is going electric too, with t...                1   \n",
       "3     Mercedes-Maybach is going electric too, with t...                1   \n",
       "4     Mercedes-Maybach is going electric too, with t...                1   \n",
       "...                                                 ...              ...   \n",
       "5955  An ecological alternative to air travel, sailb...             1504   \n",
       "5956  An ecological alternative to air travel, sailb...             1504   \n",
       "5957  An ecological alternative to air travel, sailb...             1504   \n",
       "5958  An ecological alternative to air travel, sailb...             1504   \n",
       "5959  An ecological alternative to air travel, sailb...             1504   \n",
       "\n",
       "                                               features  \n",
       "0     Is the boss himself a punch card machine? Bill...  \n",
       "1     Mercedes-Maybach is going electric too, with t...  \n",
       "2     Mercedes-Maybach is going electric too, with t...  \n",
       "3     Mercedes-Maybach is going electric too, with t...  \n",
       "4     Mercedes-Maybach is going electric too, with t...  \n",
       "...                                                 ...  \n",
       "5955  An ecological alternative to air travel, sailb...  \n",
       "5956  An ecological alternative to air travel, sailb...  \n",
       "5957  An ecological alternative to air travel, sailb...  \n",
       "5958  An ecological alternative to air travel, sailb...  \n",
       "5959  An ecological alternative to air travel, sailb...  \n",
       "\n",
       "[4701 rows x 7 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
