{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from random import choices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "import evaluate\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" # change to \"cuda\" if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', token=HF_TOKEN)\n",
    "pretrained = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", token=HF_TOKEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in pretrained.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "for layer in pretrained.bert.encoder.layer[:6]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_parquet(\"dataset/train_df.parquet\")\n",
    "data_df = data_df[data_df[\"language\"].isin([\"English\", \"Korean\"])]\n",
    "data_df[\"sentence\"] = data_df[\"title\"] + \" || \" + data_df[\"content\"]\n",
    "data_df[\"stratified_col\"] = data_df[\"impact_length_idx\"].astype(str) + data_df[\"language\"] # for train/test split\n",
    "data_df[\"resample_col\"] = data_df[\"stratified_col\"] # for resampling\n",
    "esg_dataset = Dataset.from_pandas(data_df, preserve_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_dataset = esg_dataset.class_encode_column(\"impact_length_idx\") # encode label\n",
    "train_valid = esg_dataset.class_encode_column(\"stratified_col\").train_test_split(test_size=0.25, \n",
    "                                                                                 stratify_by_column=\"stratified_col\") # encode for splits\n",
    "train_dataset = train_valid[\"train\"]\n",
    "valid_dataset = train_valid[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = sorted(train_dataset['__index_level_0__'])\n",
    "class_counts = data_df.loc[train_idx]['resample_col'].value_counts()\n",
    "majority_class = class_counts.idxmax()\n",
    "majority_count = class_counts.max()\n",
    "\n",
    "def upsample(dataset, majority_class, majority_count):\n",
    "    # upsample every class to the same size of majority class\n",
    "    \n",
    "    upsampled_datasets = []\n",
    "\n",
    "    for class_label in set(dataset['resample_col']):\n",
    "        class_dataset = dataset.filter(lambda x: x[\"resample_col\"] == class_label)\n",
    "        \n",
    "        if majority_class == class_label:   \n",
    "            upsampled_datasets.append(class_dataset)\n",
    "        else:\n",
    "            upsampled = class_dataset.select(choices(range(len(class_dataset)), k=majority_count))\n",
    "            upsampled_datasets.append(upsampled)\n",
    "            \n",
    "    return concatenate_datasets(upsampled_datasets)\n",
    "\n",
    "resampled_train = upsample(train_dataset, majority_class,majority_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sentences = [i[\"sentence\"] for i in data]\n",
    "    labels = torch.tensor([i[\"impact_length_idx\"] for i in data]).to(device)\n",
    "\n",
    "    data = tokenizer.batch_encode_plus(sentences,\n",
    "                                       truncation=True,\n",
    "                                       padding='max_length',\n",
    "                                       max_length=400,\n",
    "                                       return_tensors='pt',\n",
    "                                       return_length=True)\n",
    "\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=resampled_train,\n",
    "                                    batch_size=16,\n",
    "                                    collate_fn=collate_fn,\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True)\n",
    "\n",
    "loader_valid = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            collate_fn=collate_fn,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 3).to(device)\n",
    "        print(summary(self.fc))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = pretrained(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    output_hidden_states=True)\n",
    "\n",
    "        out = self.fc(out[\"hidden_states\"][-1][:, 0])\n",
    "\n",
    "        out = out.softmax(dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5e^4, 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=2e-5, \n",
    "                              weight_decay=0.01)\n",
    "\n",
    "# Total number of training steps\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "# Scheduler including warm-up\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_training_steps * 0.1, \n",
    "                                            num_training_steps=num_training_steps)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids)\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "        if i % 25 == 0:\n",
    "            out = out.argmax(dim=1)\n",
    "            accuracy = (out == labels).sum().item() / len(labels)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {i}, Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids)\n",
    "\n",
    "    out = out.argmax(dim=1)\n",
    "    correct += (out == labels).sum().item()\n",
    "    total += len(labels)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(\"epoch valid accuracy:\", accuracy)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()\n",
    "        \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_valid):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(out.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"0\", linewidths=.5,\n",
    "                square = True, cmap = \"Blues\")\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.xticks(ticks=np.arange(3) + 0.5, labels=[0, 1, 2], rotation=45, ha='right')\n",
    "    plt.yticks(ticks=np.arange(3) + 0.5, labels=[0, 1, 2], rotation=0)\n",
    "\n",
    "    all_sample_title = \"Confusion Matrix\"\n",
    "    plt.title(all_sample_title, size = 15)\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
