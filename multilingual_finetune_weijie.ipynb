{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bert Base Multiligual Cased Notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:22.149561500Z",
     "start_time": "2024-01-08T10:59:13.287249800Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from random import choices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_path = \"Z:/Programing_Space/DataSpell_Workspace/Research_FinMLP Competition/0. Source Data/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:22.164696200Z",
     "start_time": "2024-01-08T10:59:22.149561500Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:22.200576500Z",
     "start_time": "2024-01-08T10:59:22.165647500Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nBertForSequenceClassification                           --\n├─BertModel: 1-1                                        --\n│    └─BertEmbeddings: 2-1                              --\n│    │    └─Embedding: 3-1                              91,812,096\n│    │    └─Embedding: 3-2                              393,216\n│    │    └─Embedding: 3-3                              1,536\n│    │    └─LayerNorm: 3-4                              1,536\n│    │    └─Dropout: 3-5                                --\n│    └─BertEncoder: 2-2                                 --\n│    │    └─ModuleList: 3-6                             85,054,464\n│    └─BertPooler: 2-3                                  --\n│    │    └─Linear: 3-7                                 590,592\n│    │    └─Tanh: 3-8                                   --\n├─Dropout: 1-2                                          --\n├─Linear: 1-3                                           1,538\n================================================================================\nTotal params: 177,854,978\nTrainable params: 177,854,978\nNon-trainable params: 0\n================================================================================"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', token=HF_TOKEN)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", token=HF_TOKEN).to(device)\n",
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:55.913617100Z",
     "start_time": "2024-01-08T10:59:22.199575900Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration for Layer Freezing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for param in summary.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for layer in model.bert.encoder.layer[:6]:\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:55.931182300Z",
     "start_time": "2024-01-08T10:59:55.912614100Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load & Process dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   url  \\\n545  https://esg.businesstoday.com.tw/article/categ...   \n546  https://esg.businesstoday.com.tw/article/categ...   \n547  https://esg.businesstoday.com.tw/article/categ...   \n548  https://esg.businesstoday.com.tw/article/categ...   \n549  https://esg.businesstoday.com.tw/article/categ...   \n\n                                               title  \\\n545                    老闆本人就是打卡機？比爾蓋茲背下員工車牌，計算每人工作時數   \n546  Mercedes-Maybach也要電動化，全新賓士EQE、AMG首款電動車將齊聚慕尼黑車展！   \n547                     銅板價吸引小資族、送電到你家，光陽掀電動機車霸主卡位戰！   \n548              國際級節能減碳建築地標！陶朱隱園不只是豪宅，屋頂就裝了六台風力發電設備   \n549        台泥 Atlante Co. 獲歐盟基金挹注！建置 215 座歐洲純綠電儲能充電站   \n\n                                               content  impact_length_idx  \\\n545  日期：\\n2022-01-04\\n工作與生活的平衡在現代是所有員工流行且追求的工作模式，但對...                2.0   \n546  日期：\\n2021-09-06\\n兩年前還稱作法蘭克福車展的IAA Mobility，在確定...                0.0   \n547  日期：\\n2021-08-18\\n傳統機車龍頭光陽強勢壓境，企圖以﹁Ionex尊榮換電﹂服務...                0.0   \n548  日期：\\n2021-11-03\\n威京集團今(3)日公布全新的CIS(企業識別系統)，以藍天...                1.0   \n549  日期：\\n2022-09-22\\n台泥今日宣布子公司 NHOA 旗下專責發展電動車快充基礎設...                2.0   \n\n    language                                           sentence  \n545  Chinese  The boss himself is a punch machine?Bill Gates...  \n546  Chinese  Mercedes-Maybach also wants to be electrified....  \n547  Chinese  The price of copper board attracts petty bourg...  \n548  Chinese  International -level energy -saving carbon red...  \n549  Chinese  TSM ATLANTE Co. was noted in the EU Fund!Build...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>title</th>\n      <th>content</th>\n      <th>impact_length_idx</th>\n      <th>language</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>545</th>\n      <td>https://esg.businesstoday.com.tw/article/categ...</td>\n      <td>老闆本人就是打卡機？比爾蓋茲背下員工車牌，計算每人工作時數</td>\n      <td>日期：\\n2022-01-04\\n工作與生活的平衡在現代是所有員工流行且追求的工作模式，但對...</td>\n      <td>2.0</td>\n      <td>Chinese</td>\n      <td>The boss himself is a punch machine?Bill Gates...</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>https://esg.businesstoday.com.tw/article/categ...</td>\n      <td>Mercedes-Maybach也要電動化，全新賓士EQE、AMG首款電動車將齊聚慕尼黑車展！</td>\n      <td>日期：\\n2021-09-06\\n兩年前還稱作法蘭克福車展的IAA Mobility，在確定...</td>\n      <td>0.0</td>\n      <td>Chinese</td>\n      <td>Mercedes-Maybach also wants to be electrified....</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>https://esg.businesstoday.com.tw/article/categ...</td>\n      <td>銅板價吸引小資族、送電到你家，光陽掀電動機車霸主卡位戰！</td>\n      <td>日期：\\n2021-08-18\\n傳統機車龍頭光陽強勢壓境，企圖以﹁Ionex尊榮換電﹂服務...</td>\n      <td>0.0</td>\n      <td>Chinese</td>\n      <td>The price of copper board attracts petty bourg...</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>https://esg.businesstoday.com.tw/article/categ...</td>\n      <td>國際級節能減碳建築地標！陶朱隱園不只是豪宅，屋頂就裝了六台風力發電設備</td>\n      <td>日期：\\n2021-11-03\\n威京集團今(3)日公布全新的CIS(企業識別系統)，以藍天...</td>\n      <td>1.0</td>\n      <td>Chinese</td>\n      <td>International -level energy -saving carbon red...</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>https://esg.businesstoday.com.tw/article/categ...</td>\n      <td>台泥 Atlante Co. 獲歐盟基金挹注！建置 215 座歐洲純綠電儲能充電站</td>\n      <td>日期：\\n2022-09-22\\n台泥今日宣布子公司 NHOA 旗下專責發展電動車快充基礎設...</td>\n      <td>2.0</td>\n      <td>Chinese</td>\n      <td>TSM ATLANTE Co. was noted in the EU Fund!Build...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chn_dataset = pd.read_parquet(dataset_path+\"train_df_Chinese_translated.parquet\")\n",
    "eng_dataset = pd.read_parquet(dataset_path+\"train_df_English_translated.parquet\")\n",
    "fre_dataset = pd.read_parquet(dataset_path+\"train_df_French_translated.parquet\")\n",
    "kor_dataset = pd.read_parquet(dataset_path+\"train_df_Korean_translated.parquet\")\n",
    "del chn_dataset[\"sentence_ch\"]\n",
    "eng_dataset[\"Translation\"] = eng_dataset[\"sentence\"]\n",
    "dataset = pd.concat([chn_dataset,eng_dataset,fre_dataset,kor_dataset])\n",
    "dataset[\"sentence\"] = dataset[\"Translation\"]\n",
    "del dataset[\"Translation\"]\n",
    "dataset.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:56.575042700Z",
     "start_time": "2024-01-08T10:59:55.929181700Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset[\"stratified_col\"] = dataset[\"impact_length_idx\"].astype(str) + dataset[\"language\"] # for train/test split\n",
    "dataset[\"resample_col\"] = dataset[\"stratified_col\"] # for resampling\n",
    "esg_dataset = Dataset.from_pandas(dataset, preserve_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:56.791108700Z",
     "start_time": "2024-01-08T10:59:56.574042900Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Stringifying the column:   0%|          | 0/2358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98ce0327ef8f4b2f9ae1d36c4dabcfb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting to class labels:   0%|          | 0/2358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b78fba28ed6d48dc9067b4a480b3ec88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting to class labels:   0%|          | 0/2358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e4da7f5f7ac4e6dbb0666f96c8ba805"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esg_dataset = esg_dataset.class_encode_column(\"impact_length_idx\") # encode label\n",
    "train_valid = esg_dataset.class_encode_column(\"stratified_col\").train_test_split(test_size=0.25, stratify_by_column=\"stratified_col\")\n",
    "train_dataset = train_valid[\"train\"]\n",
    "valid_dataset = train_valid[\"test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:56.850628600Z",
     "start_time": "2024-01-08T10:59:56.741096500Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2808103bd6c74f71aca117d7d666ad2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daf8e46790ac4511929d98f081087620"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d4eca666350441b883675f3676fab79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8f1c46f28a746e288eeddf45e835079"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d148173dfd3d40368cead785e06f48ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6180464690476aa9fe41c7782c1060"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40da2e6c9e74047984ad2166b6bf804"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e1eec0127784a2686f739cdad869e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f06f4d52d65456d83ee294b377e760c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b00872231c8c41c285ac0a9aaecaaedc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef63d2ec0ae4433e9dcdc1b71a698648"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/1768 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9938084cec043eb9bf5bf308d8c2f36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_idx = sorted(train_dataset['__index_level_0__'])\n",
    "class_counts = dataset.loc[train_idx]['resample_col'].value_counts()\n",
    "majority_class = class_counts.idxmax()\n",
    "majority_count = class_counts.max()\n",
    "\n",
    "def upsample(dataset, majority_class, majority_count):\n",
    "    # upsample every class to the same size of majority class\n",
    "    upsampled_datasets = []\n",
    "\n",
    "    for class_label in set(dataset['resample_col']):\n",
    "        class_dataset = dataset.filter(lambda x: x[\"resample_col\"] == class_label)\n",
    "\n",
    "        if majority_class == class_label:\n",
    "            upsampled_datasets.append(class_dataset)\n",
    "        else:\n",
    "            upsampled = class_dataset.select(choices(range(len(class_dataset)), k=majority_count))\n",
    "            upsampled_datasets.append(upsampled)\n",
    "\n",
    "    return concatenate_datasets(upsampled_datasets)\n",
    "\n",
    "resampled_train = upsample(train_dataset, majority_class,majority_count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:57.601973400Z",
     "start_time": "2024-01-08T10:59:56.834625200Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:57.627981900Z",
     "start_time": "2024-01-08T10:59:57.606974900Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sentences = [i[\"sentence\"] for i in data]\n",
    "    labels = torch.tensor([i[\"impact_length_idx\"] for i in data]).to(device)\n",
    "\n",
    "    data = tokenizer.batch_encode_plus(sentences,\n",
    "                                       truncation=True,\n",
    "                                       padding='max_length',\n",
    "                                       max_length=400,\n",
    "                                       return_tensors='pt',\n",
    "                                       return_length=True)\n",
    "\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=resampled_train,\n",
    "                                    batch_size=16,\n",
    "                                    collate_fn=collate_fn,\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True)\n",
    "\n",
    "loader_valid = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            collate_fn=collate_fn,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:57.643490500Z",
     "start_time": "2024-01-08T10:59:57.619979700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "Linear                                   2,307\n",
      "=================================================================\n",
      "Total params: 2,307\n",
      "Trainable params: 2,307\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 3).to(device)\n",
    "        print(summary(self.fc))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    output_hidden_states=True)\n",
    "\n",
    "        out = self.fc(out[\"hidden_states\"][-1][:, 0])\n",
    "\n",
    "        out = out.softmax(dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#5e^4, 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "num_epochs = 3\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=2e-5,\n",
    "                              weight_decay=0.01)\n",
    "# Total number of training steps\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "# Scheduler including warm-up\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=num_training_steps * 0.1,\n",
    "                                            num_training_steps=num_training_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:57.655492300Z",
     "start_time": "2024-01-08T10:59:57.636487700Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:58.396202700Z",
     "start_time": "2024-01-08T10:59:57.654491700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'output_hidden_states'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (input_ids, attention_mask, token_type_ids, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m      4\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 6\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m     11\u001B[0m     torch\u001B[38;5;241m.\u001B[39mmps\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[1;32mF:\\Softwares\\Anaconda\\envs\\lawrence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\Softwares\\Anaconda\\envs\\lawrence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[11], line 8\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_ids, attention_mask, token_type_ids):\n\u001B[1;32m----> 8\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhidden_states\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][:, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     15\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39msoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mF:\\Softwares\\Anaconda\\envs\\lawrence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\Softwares\\Anaconda\\envs\\lawrence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'output_hidden_states'"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids)\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "        if i % 25 == 0:\n",
    "            out = out.argmax(dim=1)\n",
    "            accuracy = (out == labels).sum().item() / len(labels)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {i}, Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "        \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids)\n",
    "\n",
    "    out = out.argmax(dim=1)\n",
    "    correct += (out == labels).sum().item()\n",
    "    total += len(labels)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(\"epoch valid accuracy:\", accuracy)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T10:59:58.408204600Z",
     "start_time": "2024-01-08T10:59:58.397202400Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_valid):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(out.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"0\", linewidths=.5,\n",
    "                square = True, cmap = \"Blues\")\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.xticks(ticks=np.arange(3) + 0.5, labels=[0, 1, 2], rotation=45, ha='right')\n",
    "    plt.yticks(ticks=np.arange(3) + 0.5, labels=[0, 1, 2], rotation=0)\n",
    "\n",
    "    all_sample_title = \"Confusion Matrix\"\n",
    "    plt.title(all_sample_title, size = 15)\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-08T10:59:58.399202700Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
